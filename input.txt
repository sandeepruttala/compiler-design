# Lexical Analyzer or TokenSplitter in Python
•	TokenSplitter is a Python class designed to tokenize source code written in the **C programming language**.  
•	It identifies and categorizes different elements of the code, such as keywords, operators, identifiers, constants, and special symbols.  
•	The tokenization results are displayed line by line and also in a tabular format using Pandas.

## Installation
- To use TokenSplitter, simply clone this repository or download the TokenSplitter.py file and include it in your project.
## Imported Modules
- **Regex or re** - Regular expression operations  
  (https://docs.python.org/3/library/re.html)  
  to install type in cmd - _pip install re_  

 - **pandas** -  Python Data Analysis Library  
  (https://pandas.pydata.org/)  
   to install type in cmd - _pip install pandas_  

## Input & Output
- **Input**: Here we are taking input from a file.
- **Output**: It displays every token and its type line by line and also prints the table of tokens.

## Instructions
- Don't forget to modify filepath.

## Code Explaination
- The code defines a class named TokenSplitter, which is responsible for tokenizing source code written in the C programming language and categorizing the tokens into different types.

- The __init__ method initializes the class attributes, which include lists of keywords, operators, and special symbols used in the C code, as well as an empty dictionary named self.table to store the categorized tokens.

- The split_tokens method takes the code as input, removes comments (both single-line and multi-line) from the code using regular expressions (re), and then uses regex to find all words, operators, and special symbols in the code. The method returns the list of tokens.

- The identify_token_type method takes a token as input and identifies its type by checking if it matches any of the predefined lists (keywords, operators, special symbols). If it is an identifier (variable name), it checks if it follows the valid identifier naming rules. The method updates the self.table dictionary with the token type and appends the token to the corresponding category list.

- The print_table method is responsible for printing the categorized tokens in a tabular format. It first removes duplicates from the category lists using set and then finds the maximum length among all the lists to ensure that the DataFrame has equal-sized columns. It then adds empty strings to the lists to match the maximum length. Finally, it creates a DataFrame from the self.table dictionary using Pandas and prints the DataFrame with values aligned to the center.

- The main function reads the C code from the input file, creates a TokenSplitter object, tokenizes the code, identifies the type of each token, and prints the results in both a token-type format and a categorized table format using the print_table method.

- The code can be used to analyze C code, extract different tokens, and display them in an organized tabular format. It uses regular expressions and Pandas to efficiently process and present the results. The provided input file (test.txt) should contain valid C code for the program to work correctly.

## Contributing
- If you find any issues or have suggestions for improvements, feel free to open an issue or submit a pull request. Contributions are welcome!
